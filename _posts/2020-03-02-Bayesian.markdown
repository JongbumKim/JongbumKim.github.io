---
layout: post
title:  "Bayesian Theory"
author: 
date:   2020-03-02
categories: Statistics
tags:	Bayesian
use_math: true
description: 
cover:  "/assets/instacode.png"
---


## Conditional probability ?

Bayes' theorem is the theoretical underpinning of most of what we do within the Bayesian statistical framework.
Conditional probability is when we're trying to consider two events that are related to each other.
So we can ask, what is the probability of event A given that we know event B happened?
This is defined as the probability that both events A and B happened divided by the probability that event B happens.

$P(A \mid B) = P(A \cap B)$

For example, consider a class of 30 students.
Suppose within this class, there are 9 female students.
Suppose also, we have 12 computer science majors.
And of which, 4 are female. So then, we can ask questions about probabilities of the segment population.

|              | Female | Female | Total |
|--------------|--------|--------|-------|
| CS Major     | 4      | 8      | 12    |
| Not CS Major | 5      | 13     | 18    |
| Total        | 9      | 21     | 30    |



$P(F) = \frac{9}{30} = \frac{3}{10}$

$P(CS) = \frac{12}{30} = \frac{2}{5}$

$P(F \cap CS) = \frac{4}{30} = \frac{2}{15}$

$P(F \mid CS) = \frac{P(F \cap CS)}{P(CS)} = \frac{2/15}{2/5} = \frac{1}{3}$

$P(F \mid CS^{c}) = \frac{P(F \cap CS^{c})}{P(CS^{c})} = \frac{5/30}{18/30} = \frac{5}{12}$

--------------------------------
## Independence ?

There's a concept of independence, which is when one event doesn't depend on the other. When two events are independent, we have that the probability of A given B is equal to just the probability of A, it doesn't matter whether, or not B occurred. When this is true, we also get that the probability of A and B happening is just the probability of A times the probability of B. This is a useful equality that we'll use throughout this course.

$P(A \mid B) = P(A)$
then,
$P(A \cap B)=P(A)P(B)$

In this case, we can see that the probability of being a female given they're computer scientist is not equal to the marginal probability that they're female.
And so, being female and being computer science are not independent.

$P(F \mid CS) \neq P(F)$ 

--------------------------------
## Bayes' theorem ?

$P(A \mid B) = \frac{P(B \mid A)P(A)}{P(B \mid A)P(A) + P(B \mid A^{c})P(A^{c})} = \frac{P(A \cap B)}{P(B)}$

So to work this out in the context of the example of computer science and females in the class.

We can say,

$P(CS \mid F) = \frac{P(F \mid CS)P(CS)}{P(F \mid CS)P(CS) + P(F \mid CS^{c})P(CS^{c})}$
             $= \frac{(\frac{1}{3})(\frac{2}{5})}{(\frac{1}{3})(\frac{2}{5})+(\frac{5}{18})(\frac{3}{5})}=\frac{4}{9}$
             
$P(CS \mid F) = \frac{P(CS \cap F)}{P(F)} = \frac{4/30}{9/30} = \frac{4}{9}$

Another example was an early test for HIV antibodies known as the ELISA test. 

In that case,

$P(+ \mid HIV) = 0.977$

$P(- \mid no HIV) = 0.926$

So this is a pretty accurate test. Today's tests are much more accurate, but in the early days this was still pretty good.

That point a study found that among North American's, probability that a North American would have HIV was about 0.0026. 

$P(HIV) = 0.0026$

So then we could ask,

if we randomly selected someone from North America and we tested them and they tested positive for HIV,

what's the probability that they actually have HIV given they've tested positive.
$P(HIV \mid +)$

This case we don't have all the information to compute it directly as easily but we have the information in the reverse direction of conditioning,

and so it's the perfect time to use Bayes' Theorem.

$P(HIV \mid +) = \frac{P(+ \mid HIV)P(HIV)}{P(+ \mid HIV)P(HIV) + P(+ \mid no HIV)P(no HIV)}$

Before we go any further, I ask you to stop and think briefly.

This is over 90% accurate, what sort of number do you expect to get in this case?

let's do the calculation.

The probability they test positive given they have HIV is 0.977. $P(HIV \mid +) = 0.977$

The probability that they have HIV is 0.0026.

 - $P(HIV) = 0.0026$

The probability they test positive given they don't have HIV, that's 1 minus $P(1- \mid no HIV)$.

 - $P(1 - 0.926)$

The probability that they don't have HIV, that's 1 minus $P(HIV)$.
 - $P(1 - 0.0026)$


If we now plug that into a calculator.

$P(HIV \mid +) = \frac{(.977)(.0026)}{(.977)(.0026)+(1-.926)(1-.0026)} = .033$

We get this probability to be 0.033.

The probability they have HIV is less then 4%, even though they've tested positive on a test that is nominally quite accurate.

Is this surprising? It is for most people. Why is this so?


It's because this is a rare disease and this is actually fairly common a problem for rare diseases.

The number of false positives, greatly outnumbers the true positives because it's a rare disease.

So even though the test is very accurate, we get more false positives than we get true positives.

This obviously has important policy implications for things like mandatory testing.

It makes much more sense to test in a sub population where the prevalence of HIV is higher, rather than in a general population where it's quite rare.



To conclude,

Bayes' Theorem is an important part of our approach to Bayesian statistics.

We can use it to update our information. We start with prior beliefs, we'll collect data, we'll then condition on the data to lead to our posterior beliefs. Bayes' Theorem is the coherent way to do this updating.



--------------------------------

The simple form of Bayes Theorem involves two discrete events:

$P(A \mid B) = \frac{P(A \cap B)}{P(B)} = \frac{P(B \mid A)P(A)}{P(B \mid A)P(A) + P(B \mid A^{c})P(A^{c})}$

When there are three possible outcomes $A_{1}, A_{2}$, and $A_{3}$ such that exactly one of these must happen,

then Bayes Theorem expands to:

$P(A_{1} \mid B) = \frac{P(B \mid A_{1})P(A_{1})}{P(B \mid A_{1})P(A_{1}) + P(B \mid A_{2})P(A_{2}) + P(B \mid A_{3})P(A_{3})}$

If the events $A_{1}$, . . . , $A_{m}$ form a partition of the space (exactly one of the $A_{i}$’s must occur, i.e., the $A_{i}$
’s are mutually exclusive and $\sum_{i=1}^{m}P(A_{i}) = 1$),

then we can write Bayes Theorem as:

$P(A_{1} \mid B) = \frac{P(B \mid A_{1})P(A_{1})}{\sum_{i=1}^{m}P(B \mid A_{i})P(A_{i})}$

